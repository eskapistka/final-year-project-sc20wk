{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature importance by gender</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Load the dataset</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif, RFE\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# load adhd dataset\n",
    "df = pd.read_csv('questionnaire_dataset.csv', sep=';')\n",
    "feature_cols = desired_columns = ['gender', 'group'] + [f'tr{i}' for i in range(1, 44)] + [f'dass{i}' for i in range(1, 22)]\n",
    "df = df[feature_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Screening questionnaire based on previous analysis</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Critère DSM-5</th>\n",
       "      <th>English Item (Author's suggestion)</th>\n",
       "      <th>question_code</th>\n",
       "      <th>dsm5_criteria</th>\n",
       "      <th>symptom_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>I have trouble maintaining my attention at work.</td>\n",
       "      <td>tr4</td>\n",
       "      <td>Often has difficulty sustaining attention in t...</td>\n",
       "      <td>inattention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>I have trouble staying focused during conversa...</td>\n",
       "      <td>tr6</td>\n",
       "      <td>Often has difficulty sustaining attention in t...</td>\n",
       "      <td>inattention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>My mind is often elsewhere, even when there is...</td>\n",
       "      <td>tr8</td>\n",
       "      <td>Often does not seem to listen when spoken to d...</td>\n",
       "      <td>inattention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>I have difficulty completing my tasks (work, h...</td>\n",
       "      <td>tr10</td>\n",
       "      <td>Often does not follow through on instructions ...</td>\n",
       "      <td>inattention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "      <td>I have difficulty staying focused during my ac...</td>\n",
       "      <td>tr11</td>\n",
       "      <td>Often does not follow through on instructions ...</td>\n",
       "      <td>inattention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E</td>\n",
       "      <td>It is difficult for me to organize tasks that ...</td>\n",
       "      <td>tr14</td>\n",
       "      <td>Often has difficulty organizing tasks and acti...</td>\n",
       "      <td>inattention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F</td>\n",
       "      <td>I tend to avoid tasks that require sustained m...</td>\n",
       "      <td>tr15</td>\n",
       "      <td>Often avoids, dislikes, or is reluctant to eng...</td>\n",
       "      <td>inattention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>G</td>\n",
       "      <td>I often lose things I need for my work</td>\n",
       "      <td>tr19</td>\n",
       "      <td>Often loses things necessary for tasks or acti...</td>\n",
       "      <td>inattention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>H</td>\n",
       "      <td>I am easily distracted by my environment</td>\n",
       "      <td>tr21</td>\n",
       "      <td>Is often easily distracted by extraneous stimu...</td>\n",
       "      <td>inattention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b</td>\n",
       "      <td>I often leave my seat unnecessarily during a m...</td>\n",
       "      <td>tr28</td>\n",
       "      <td>Often leaves seat in situations when remaining...</td>\n",
       "      <td>hyperactivity/impulsivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>b</td>\n",
       "      <td>I often leave my seat unnecessarily at work.</td>\n",
       "      <td>tr29</td>\n",
       "      <td>Often leaves seat in situations when remaining...</td>\n",
       "      <td>hyperactivity/impulsivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c</td>\n",
       "      <td>The people around me think that I am a restles...</td>\n",
       "      <td>tr31</td>\n",
       "      <td>Often runs about or climbs in situations where...</td>\n",
       "      <td>hyperactivity/impulsivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>e</td>\n",
       "      <td>It's hard for me to sit still for any length o...</td>\n",
       "      <td>tr36</td>\n",
       "      <td>Is often “on the go,” acting as if “driven by ...</td>\n",
       "      <td>hyperactivity/impulsivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>g (h,f)</td>\n",
       "      <td>I find it difficult to wait my turn in a conve...</td>\n",
       "      <td>tr40</td>\n",
       "      <td>Often blurts out an answer before a question h...</td>\n",
       "      <td>hyperactivity/impulsivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>i</td>\n",
       "      <td>I often impose myself in conversations.</td>\n",
       "      <td>tr43</td>\n",
       "      <td>Often interrupts or intrudes on others (e.g., ...</td>\n",
       "      <td>hyperactivity/impulsivity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Critère DSM-5                 English Item (Author's suggestion)  \\\n",
       "0              B   I have trouble maintaining my attention at work.   \n",
       "1              B  I have trouble staying focused during conversa...   \n",
       "2              C  My mind is often elsewhere, even when there is...   \n",
       "3              D  I have difficulty completing my tasks (work, h...   \n",
       "4              D  I have difficulty staying focused during my ac...   \n",
       "5              E  It is difficult for me to organize tasks that ...   \n",
       "6              F  I tend to avoid tasks that require sustained m...   \n",
       "7              G             I often lose things I need for my work   \n",
       "8              H           I am easily distracted by my environment   \n",
       "9              b  I often leave my seat unnecessarily during a m...   \n",
       "10             b       I often leave my seat unnecessarily at work.   \n",
       "11             c  The people around me think that I am a restles...   \n",
       "12             e  It's hard for me to sit still for any length o...   \n",
       "13       g (h,f)  I find it difficult to wait my turn in a conve...   \n",
       "14             i            I often impose myself in conversations.   \n",
       "\n",
       "   question_code                                      dsm5_criteria  \\\n",
       "0            tr4  Often has difficulty sustaining attention in t...   \n",
       "1            tr6  Often has difficulty sustaining attention in t...   \n",
       "2            tr8  Often does not seem to listen when spoken to d...   \n",
       "3           tr10  Often does not follow through on instructions ...   \n",
       "4           tr11  Often does not follow through on instructions ...   \n",
       "5           tr14  Often has difficulty organizing tasks and acti...   \n",
       "6           tr15  Often avoids, dislikes, or is reluctant to eng...   \n",
       "7           tr19  Often loses things necessary for tasks or acti...   \n",
       "8           tr21  Is often easily distracted by extraneous stimu...   \n",
       "9           tr28  Often leaves seat in situations when remaining...   \n",
       "10          tr29  Often leaves seat in situations when remaining...   \n",
       "11          tr31  Often runs about or climbs in situations where...   \n",
       "12          tr36  Is often “on the go,” acting as if “driven by ...   \n",
       "13          tr40  Often blurts out an answer before a question h...   \n",
       "14          tr43  Often interrupts or intrudes on others (e.g., ...   \n",
       "\n",
       "             symptom_category  \n",
       "0                 inattention  \n",
       "1                 inattention  \n",
       "2                 inattention  \n",
       "3                 inattention  \n",
       "4                 inattention  \n",
       "5                 inattention  \n",
       "6                 inattention  \n",
       "7                 inattention  \n",
       "8                 inattention  \n",
       "9   hyperactivity/impulsivity  \n",
       "10  hyperactivity/impulsivity  \n",
       "11  hyperactivity/impulsivity  \n",
       "12  hyperactivity/impulsivity  \n",
       "13  hyperactivity/impulsivity  \n",
       "14  hyperactivity/impulsivity  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the screening questionnaire \n",
    "screening_questions = pd.read_csv('screening_questions.csv', sep=';')\n",
    "screening_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Balance the dataset using ADASYN</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>group</th>\n",
       "      <th>tr1</th>\n",
       "      <th>tr2</th>\n",
       "      <th>tr3</th>\n",
       "      <th>tr4</th>\n",
       "      <th>tr5</th>\n",
       "      <th>tr6</th>\n",
       "      <th>tr7</th>\n",
       "      <th>tr8</th>\n",
       "      <th>...</th>\n",
       "      <th>dass12</th>\n",
       "      <th>dass13</th>\n",
       "      <th>dass14</th>\n",
       "      <th>dass15</th>\n",
       "      <th>dass16</th>\n",
       "      <th>dass17</th>\n",
       "      <th>dass18</th>\n",
       "      <th>dass19</th>\n",
       "      <th>dass20</th>\n",
       "      <th>dass21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>356.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>356.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.502809</td>\n",
       "      <td>0.483146</td>\n",
       "      <td>3.553371</td>\n",
       "      <td>3.730337</td>\n",
       "      <td>4.797753</td>\n",
       "      <td>4.446629</td>\n",
       "      <td>3.904494</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.334270</td>\n",
       "      <td>4.280899</td>\n",
       "      <td>...</td>\n",
       "      <td>1.561798</td>\n",
       "      <td>1.435393</td>\n",
       "      <td>1.311798</td>\n",
       "      <td>1.019663</td>\n",
       "      <td>0.772472</td>\n",
       "      <td>1.429775</td>\n",
       "      <td>1.629213</td>\n",
       "      <td>1.095506</td>\n",
       "      <td>1.039326</td>\n",
       "      <td>1.205056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500696</td>\n",
       "      <td>0.500419</td>\n",
       "      <td>1.585130</td>\n",
       "      <td>1.523628</td>\n",
       "      <td>1.421602</td>\n",
       "      <td>1.404205</td>\n",
       "      <td>1.529754</td>\n",
       "      <td>1.670582</td>\n",
       "      <td>1.696078</td>\n",
       "      <td>1.618476</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006515</td>\n",
       "      <td>0.877760</td>\n",
       "      <td>0.952965</td>\n",
       "      <td>0.971223</td>\n",
       "      <td>0.826617</td>\n",
       "      <td>1.017099</td>\n",
       "      <td>0.962766</td>\n",
       "      <td>1.049148</td>\n",
       "      <td>1.047397</td>\n",
       "      <td>1.090330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           gender       group         tr1         tr2         tr3         tr4  \\\n",
       "count  356.000000  356.000000  356.000000  356.000000  356.000000  356.000000   \n",
       "mean     0.502809    0.483146    3.553371    3.730337    4.797753    4.446629   \n",
       "std      0.500696    0.500419    1.585130    1.523628    1.421602    1.404205   \n",
       "min      0.000000    0.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      0.000000    0.000000    2.000000    2.000000    4.000000    4.000000   \n",
       "50%      1.000000    0.000000    4.000000    4.000000    5.000000    5.000000   \n",
       "75%      1.000000    1.000000    5.000000    5.000000    6.000000    5.000000   \n",
       "max      1.000000    1.000000    6.000000    6.000000    6.000000    6.000000   \n",
       "\n",
       "              tr5         tr6         tr7         tr8  ...      dass12  \\\n",
       "count  356.000000  356.000000  356.000000  356.000000  ...  356.000000   \n",
       "mean     3.904494    3.750000    3.334270    4.280899  ...    1.561798   \n",
       "std      1.529754    1.670582    1.696078    1.618476  ...    1.006515   \n",
       "min      1.000000    1.000000    1.000000    1.000000  ...    0.000000   \n",
       "25%      3.000000    2.000000    2.000000    3.000000  ...    1.000000   \n",
       "50%      4.000000    4.000000    4.000000    5.000000  ...    2.000000   \n",
       "75%      5.000000    5.000000    5.000000    6.000000  ...    2.000000   \n",
       "max      6.000000    6.000000    6.000000    6.000000  ...    3.000000   \n",
       "\n",
       "           dass13      dass14      dass15      dass16      dass17      dass18  \\\n",
       "count  356.000000  356.000000  356.000000  356.000000  356.000000  356.000000   \n",
       "mean     1.435393    1.311798    1.019663    0.772472    1.429775    1.629213   \n",
       "std      0.877760    0.952965    0.971223    0.826617    1.017099    0.962766   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000    1.000000    0.000000    0.000000    1.000000    1.000000   \n",
       "50%      1.000000    1.000000    1.000000    1.000000    1.000000    2.000000   \n",
       "75%      2.000000    2.000000    2.000000    1.000000    2.000000    2.000000   \n",
       "max      3.000000    3.000000    3.000000    3.000000    3.000000    3.000000   \n",
       "\n",
       "           dass19      dass20      dass21  \n",
       "count  356.000000  356.000000  356.000000  \n",
       "mean     1.095506    1.039326    1.205056  \n",
       "std      1.049148    1.047397    1.090330  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      1.000000    1.000000    1.000000  \n",
       "75%      2.000000    2.000000    2.000000  \n",
       "max      3.000000    3.000000    3.000000  \n",
       "\n",
       "[8 rows x 66 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adasyn = ADASYN(random_state=42)\n",
    "X = df.copy().drop(columns=['gender'])\n",
    "y = df['gender'].copy() # men = 1 / women = 0\n",
    "# apply ADASYN oversampling to balance the dataset\n",
    "X_balanced, y_balanced = adasyn.fit_resample(X, y)\n",
    "balanced_df = pd.concat([y_balanced, X_balanced], axis=1)\n",
    "balanced_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Split the balanced dataset by gender for train, test sets</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset by gender \n",
    "balanced_df_women = balanced_df[balanced_df['gender'] == 0]\n",
    "balanced_df_men = balanced_df[balanced_df['gender'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split it further into features and target variable\n",
    "X_women = balanced_df_women.copy().drop(columns=['group', 'gender']).filter(regex='tr')\n",
    "y_women = balanced_df_women['group'].copy() # adhd = 1 / no adhd = -1\n",
    "\n",
    "X_men = balanced_df_men.copy().drop(columns=['group', 'gender']).filter(regex='tr')\n",
    "y_men = balanced_df_men['group'].copy() # adhd = 1 / no adhd = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# further filter the features to extract only the ones in the narrowed down version of the questionnaire\n",
    "screening_qs_codes = screening_questions['question_code'].unique()\n",
    "X_women = X_women.filter(items=screening_qs_codes, axis=1)\n",
    "X_men = X_men.filter(items=screening_qs_codes, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Split the data further into Train, Test and Validation sets</h5>\n",
    "<p>\n",
    "Further division of the dataset into training, test and validation set is a common technique used to improve models without data leakage. \n",
    "\n",
    "The training set is used to train the model.\n",
    "The validation set is used to evaluate the performance of the model during training and fine-tune it's hyperparameters.\n",
    "\n",
    "The test set is used to evaluate the final performance of the trained model. It represents unseen data that the model hasn't encountered during training or validation. Using a test set allows for unbiased estimate of the model's performance in real-world scenario.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified splitting to preserve a balanced class split according to diagnosis\n",
    "# women\n",
    "X_train_val_women, X_test_women, y_train_val_women, y_test_women = train_test_split(X_women, y_women, test_size=0.1, stratify=y_women, random_state=42) \n",
    "X_train_women, X_val_women, y_train_women, y_val_women = train_test_split(X_train_val_women, y_train_val_women, test_size=0.25, stratify=y_train_val_women, random_state=42) \n",
    "\n",
    "# men\n",
    "X_train_val_men, X_test_men, y_train_val_men, y_test_men = train_test_split(X_men, y_men, test_size=0.1, stratify=y_men, random_state=42) \n",
    "X_train_men, X_val_men, y_train_men, y_val_men = train_test_split(X_train_val_men, y_train_val_men, test_size=0.25, stratify=y_train_val_men, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Scaling the data using StandardScaler</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_women = scaler.fit_transform(X_train_women)\n",
    "X_val_scaled_women = scaler.transform(X_val_women)\n",
    "X_test_scaled_women = scaler.transform(X_test_women)\n",
    "\n",
    "X_train_scaled_men = scaler.fit_transform(X_train_men)\n",
    "X_val_scaled_men = scaler.transform(X_val_men)\n",
    "X_test_scaled_men = scaler.transform(X_test_men)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature Importance for women</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b27d0b71acf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# chi2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mselect_chi2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train_women_chi2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_chi2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled_women\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_women\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# information gain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0mscore_func_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_func_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_func_ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mglobal_skip_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip_parameter_validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mfunc_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\u001b[0m in \u001b[0;36mchi2\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input X must be non-negative.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;31m# Use a sparse representation for Y by default to reduce memory usage when\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input X must be non-negative."
     ]
    }
   ],
   "source": [
    "# 1. feature extraction chi2 and information gain\n",
    "# chi2\n",
    "select_chi2 = SelectKBest(score_func=chi2, k=all)\n",
    "X_train_women_chi2 = select_chi2.fit_transform(X_train_scaled_women, y_train_women)\n",
    "\n",
    "# information gain\n",
    "mutual_info_scores = mutual_info_classif(X_train_scaled_women, y_train_women)\n",
    "selected_features_indices = (-mutual_info_scores).argsort()\n",
    "X_train_women_info_gain = X_train_women[:, selected_features_indices]\n",
    "\n",
    "\n",
    "# 2. train classifiers with GridSearchCV (Logistic Regression, AdaBoost, Support Vector Machine, Random Forest, K-Nearest Neighbours)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. analyse feature importance from the best perfoming classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Select relevant features (e.g., symptoms demonstrating gender-specific patterns)\n",
    "feature_cols = ['gender'] + [f'tr{i}' for i in range(1, 44)] + [f'dass{i}' for i in range(1, 22)]\n",
    "y = X_resampled_adasyn['group']  # adhd = 1 / no-adhd = 0\n",
    "X = X_resampled_adasyn[feature_cols]\n",
    "\n",
    "# Engineer new features capturing distinct symptom presentation between women and men (if needed)\n",
    "\n",
    "X_women = X_resampled_adasyn[X_resampled_adasyn['gender'] == 0]\n",
    "y_women = X[X['gender'] == 0]\n",
    "X_men = X[X['gender'] == 1]\n",
    "y_men = X[X['gender'] == 1]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature selection using SelectKBest with chi-square test\n",
    "k_best = SelectKBest(score_func=chi2, k=15)  # Select top 10 features\n",
    "X_train_kbest = k_best.fit_transform(X_train, y_train)\n",
    "X_test_kbest = k_best.transform(X_test)\n",
    "selected_features_indices = k_best.get_support(indices=True)\n",
    "selected_features = X.columns[selected_features_indices]\n",
    "\n",
    "print(selected_features)\n",
    "\n",
    "# Model development and evaluation\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'k-Nearest Neighbors': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Train model\n",
    "    model.fit(X_train_kbest, y_train)\n",
    "    \n",
    "    # Evaluate model\n",
    "    y_pred = model.predict(X_test_kbest)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Accuracy: {accuracy}\")\n",
    "    print(f\"  Precision: {precision}\")\n",
    "    print(f\"  Recall: {recall}\")\n",
    "    print(f\"  F1-score: {f1}\")\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_kbest, y_train, cv=5)\n",
    "    print(f\"  Cross-validation scores: {cv_scores}\")\n",
    "    print(f\"  Mean CV accuracy: {cv_scores.mean()}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature Importance for men</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. feature extraction chi2 and information gain\n",
    "\n",
    "\n",
    "\n",
    "# 2. train classifiers with GridSearchCV (Logistic Regression, AdaBoost, Support Vector Machine, Random Forest, K-Nearest Neighbours)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. analyse feature importance from the best perfoming classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
